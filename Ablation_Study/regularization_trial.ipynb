{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subfolders\n",
    "subfolders = [\"beyza\", \"zeynep\", \"ezgi\"]\n",
    "\n",
    "# Set the path to the root directory\n",
    "root_path = r\"C:\\Users\\Beyza\\Desktop\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "valid_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(root_path, subfolder, \"bolunmus_gorseller\")\n",
    "    \n",
    "    for folder_name in os.listdir(subfolder_path):\n",
    "        folder_path = os.path.join(subfolder_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if any(file_name.lower().endswith(ext) for ext in valid_extensions):\n",
    "                    image_path = os.path.join(folder_path, file_name)\n",
    "                    # Extract label from the file name (assuming the label is the third part split by underscores)\n",
    "                    label = file_name.split('_')[2]\n",
    "                    img = cv2.imread(image_path)\n",
    "                    if img is None:\n",
    "                        print(f\"Failed to load image: {image_path}\")\n",
    "                    else:\n",
    "                        img = cv2.resize(img, (64, 64))  # Resize the image to a consistent size\n",
    "                        images.append(img)\n",
    "                        labels.append(label)\n",
    "                        # Rest of the code remains unchanged\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "963931a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 21042\n",
      "Number of labels: 21042\n",
      "Epoch 1/30\n",
      "527/527 [==============================] - 41s 71ms/step - loss: 4.8648 - accuracy: 0.0119 - val_loss: 4.5455 - val_accuracy: 0.0150\n",
      "Epoch 2/30\n",
      "527/527 [==============================] - 35s 67ms/step - loss: 4.5087 - accuracy: 0.0184 - val_loss: 4.5953 - val_accuracy: 0.0190\n",
      "Epoch 3/30\n",
      "527/527 [==============================] - 35s 67ms/step - loss: 4.4311 - accuracy: 0.0322 - val_loss: 4.3738 - val_accuracy: 0.0421\n",
      "Epoch 4/30\n",
      "527/527 [==============================] - 37s 70ms/step - loss: 4.2266 - accuracy: 0.0569 - val_loss: 4.2641 - val_accuracy: 0.0513\n",
      "Epoch 5/30\n",
      "527/527 [==============================] - 37s 70ms/step - loss: 3.9106 - accuracy: 0.1041 - val_loss: 3.9171 - val_accuracy: 0.1072\n",
      "Epoch 6/30\n",
      "527/527 [==============================] - 38s 71ms/step - loss: 3.6061 - accuracy: 0.1457 - val_loss: 4.0075 - val_accuracy: 0.1095\n",
      "Epoch 7/30\n",
      "527/527 [==============================] - 35s 67ms/step - loss: 3.3921 - accuracy: 0.1902 - val_loss: 3.5705 - val_accuracy: 0.1720\n",
      "Epoch 8/30\n",
      "527/527 [==============================] - 36s 69ms/step - loss: 3.2379 - accuracy: 0.2134 - val_loss: 3.3128 - val_accuracy: 0.2069\n",
      "Epoch 9/30\n",
      "527/527 [==============================] - 38s 71ms/step - loss: 3.1445 - accuracy: 0.2332 - val_loss: 3.2952 - val_accuracy: 0.2252\n",
      "Epoch 10/30\n",
      "527/527 [==============================] - 36s 67ms/step - loss: 3.0353 - accuracy: 0.2563 - val_loss: 3.4742 - val_accuracy: 0.1905\n",
      "Epoch 11/30\n",
      "527/527 [==============================] - 37s 71ms/step - loss: 2.9732 - accuracy: 0.2702 - val_loss: 3.3807 - val_accuracy: 0.2174\n",
      "Epoch 12/30\n",
      "527/527 [==============================] - 45s 85ms/step - loss: 2.8898 - accuracy: 0.2819 - val_loss: 3.0953 - val_accuracy: 0.2428\n",
      "Epoch 13/30\n",
      "527/527 [==============================] - 36s 68ms/step - loss: 2.8337 - accuracy: 0.2992 - val_loss: 3.0037 - val_accuracy: 0.2640\n",
      "Epoch 14/30\n",
      "527/527 [==============================] - 40s 76ms/step - loss: 2.7641 - accuracy: 0.3103 - val_loss: 2.9572 - val_accuracy: 0.2770\n",
      "Epoch 15/30\n",
      "527/527 [==============================] - 57s 107ms/step - loss: 2.7174 - accuracy: 0.3238 - val_loss: 2.9845 - val_accuracy: 0.2925\n",
      "Epoch 16/30\n",
      "527/527 [==============================] - 60s 114ms/step - loss: 2.6262 - accuracy: 0.3470 - val_loss: 3.0210 - val_accuracy: 0.2732\n",
      "Epoch 17/30\n",
      "527/527 [==============================] - 61s 116ms/step - loss: 2.5843 - accuracy: 0.3525 - val_loss: 2.7638 - val_accuracy: 0.3217\n",
      "Epoch 18/30\n",
      "527/527 [==============================] - 61s 116ms/step - loss: 2.4967 - accuracy: 0.3705 - val_loss: 2.7407 - val_accuracy: 0.3222\n",
      "Epoch 19/30\n",
      "527/527 [==============================] - 57s 109ms/step - loss: 2.4382 - accuracy: 0.3874 - val_loss: 2.7082 - val_accuracy: 0.3312\n",
      "Epoch 20/30\n",
      "527/527 [==============================] - 59s 111ms/step - loss: 2.3808 - accuracy: 0.4008 - val_loss: 2.6405 - val_accuracy: 0.3409\n",
      "Epoch 21/30\n",
      "527/527 [==============================] - 61s 116ms/step - loss: 2.3274 - accuracy: 0.4079 - val_loss: 2.7248 - val_accuracy: 0.3407\n",
      "Epoch 22/30\n",
      "527/527 [==============================] - 65s 124ms/step - loss: 2.2603 - accuracy: 0.4248 - val_loss: 2.8902 - val_accuracy: 0.3162\n",
      "Epoch 23/30\n",
      "527/527 [==============================] - 60s 113ms/step - loss: 2.2406 - accuracy: 0.4317 - val_loss: 2.6587 - val_accuracy: 0.3497\n",
      "Epoch 24/30\n",
      "527/527 [==============================] - 59s 112ms/step - loss: 2.1550 - accuracy: 0.4508 - val_loss: 2.6599 - val_accuracy: 0.3419\n",
      "Epoch 25/30\n",
      "527/527 [==============================] - 60s 114ms/step - loss: 2.1122 - accuracy: 0.4654 - val_loss: 2.5177 - val_accuracy: 0.3801\n",
      "Epoch 26/30\n",
      "527/527 [==============================] - 59s 111ms/step - loss: 2.0653 - accuracy: 0.4759 - val_loss: 2.4028 - val_accuracy: 0.4086\n",
      "Epoch 27/30\n",
      "527/527 [==============================] - 70s 132ms/step - loss: 2.0176 - accuracy: 0.4907 - val_loss: 2.3738 - val_accuracy: 0.4117\n",
      "Epoch 28/30\n",
      "527/527 [==============================] - 63s 120ms/step - loss: 1.9685 - accuracy: 0.4996 - val_loss: 2.4388 - val_accuracy: 0.3951\n",
      "Epoch 29/30\n",
      "527/527 [==============================] - 60s 114ms/step - loss: 1.9363 - accuracy: 0.5094 - val_loss: 2.3839 - val_accuracy: 0.4172\n",
      "Epoch 30/30\n",
      "527/527 [==============================] - 60s 114ms/step - loss: 1.8878 - accuracy: 0.5221 - val_loss: 2.4042 - val_accuracy: 0.4196\n",
      "132/132 [==============================] - 4s 33ms/step - loss: 2.4042 - accuracy: 0.4196\n",
      "Test loss: 2.4042, Test accuracy: 41.96%\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Use softmax for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
