{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94038330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8290833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subfolders\n",
    "subfolders = [\"beyza\", \"zeynep\", \"ezgi\"]\n",
    "\n",
    "# Set the path to the root directory\n",
    "root_path = r\"C:\\Users\\Beyza\\Desktop\\project\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "valid_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(root_path, subfolder)\n",
    "\n",
    "    for folder_name in os.listdir(subfolder_path):\n",
    "        folder_path = os.path.join(subfolder_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if any(file_name.lower().endswith(ext) for ext in valid_extensions):\n",
    "                    image_path = os.path.join(folder_path, file_name)\n",
    "                    label = file_name.split('_')[2]\n",
    "                    img = cv2.imread(image_path)\n",
    "                    if img is None:\n",
    "                        print(f\"Failed to load image: {image_path}\")\n",
    "                    else:\n",
    "                        img = cv2.resize(img, (64, 64))\n",
    "                        images.append(img)\n",
    "                        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84fce5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed277f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331a5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beyza\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model with glorot_uniform initializer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3906917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer with a custom learning rate (e.g., 0.001)\n",
    "custom_learning_rate = 0.001\n",
    "custom_optimizer = Adam(learning_rate=custom_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18776155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image data generator\n",
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1531a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the custom optimizer\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26fa17d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 789. MiB for an array with shape (16833, 64, 64, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a generator for training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a generator for validation data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow(X_test, y_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1103\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1091\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1102\u001b[0m ):\n\u001b[1;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumpyArrayIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:609\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    607\u001b[0m             y \u001b[38;5;241m=\u001b[39m y[split_idx:]\n\u001b[1;32m--> 609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc \u001b[38;5;241m=\u001b[39m x_misc\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 789. MiB for an array with shape (16833, 64, 64, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "# Create a generator for training data\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "# Create a generator for validation data\n",
    "validation_generator = datagen.flow(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962da896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time before compilation\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80901a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_2 = model.fit(X_train, y_train, epochs=40, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94626116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the end time after compilation\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the compilation time\n",
    "compilation_time = end_time - start_time\n",
    "print(f\"Model compilation time: {compilation_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and validation accuracy graphs\n",
    "plt.plot(history_2.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4f579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
